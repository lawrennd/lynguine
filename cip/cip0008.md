---
id: "cip0008"
title: "Lynguine Server Mode for Fast Repeated Access"
status: "Proposed"
priority: "High"
effort: "Large"
type: "architecture"
created: "2026-01-03"
last_updated: "2026-01-03"
owner: "lawrennd"
github_issue: null
dependencies: null
---

# CIP-0008: Lynguine Server Mode for Fast Repeated Access

## Status

- [x] Proposed: 2026-01-03
- [ ] Accepted
- [ ] Implemented
- [ ] Closed

## Description

Implement a server mode for lynguine that allows long-running processes to serve multiple data access requests without repeatedly paying startup costs. This addresses the performance requirement (REQ-0007) where applications like lamd need to access lynguine functionality multiple times in quick succession.

## Motivation

### The Problem

Applications like lamd currently call lynguine multiple times per operation:
- Each call requires full Python interpreter startup
- Import overhead (pandas, numpy, etc.) on every call
- Configuration parsing and initialization on every call
- Total time = (startup_cost × N_calls) + actual_work

**Current Performance** (needs measurement):
- Startup time: ? seconds (to be profiled)
- Per-operation overhead: ? seconds
- Total for N operations: startup × N

This makes lynguine impractical for:
- CLI tools that process batches of files
- Applications with frequent data access patterns
- Interactive workflows requiring multiple queries

### Why This Matters

**For lamd**:
- Needs to access multiple lynguine-managed files per operation
- Startup overhead dominates execution time
- Poor user experience

**For future applications**:
- Limits adoption for CLI tools
- Makes batch processing impractical
- Prevents interactive use cases

## Investigation and Analysis

### Profiling Results (Completed 2026-01-03)

**Environment**: macOS, Python 3.11 (conda), lynguine in development mode

**Key Finding**: Import costs dominate startup time at **~1.9 seconds per cold start**.

#### Startup Time Breakdown

```
Major Dependency Import Times:
  pandas              :  1.223s  (63% of total)
  numpy               :  0.000s  (already imported by pandas)
  yaml                :  0.019s  (1%)
  liquid              :  0.154s  (8%)

Lynguine Component Import Times:
  lynguine            :  0.548s  (28% of total)
  (submodules cached after initial import)

Summary:
  Total startup time:   1.947s
  Dependencies:         1.396s (72%)
  Lynguine components:  0.552s (28%)
```

**Analysis**:
- **pandas dominates**: 1.223s (63%) - cannot be optimized, must be amortized
- **lynguine initialization**: 0.548s (28%) - includes pandas triggering
- **Subsequent imports fast**: Cached after first import (Python module cache)

#### Memory Usage

```
Python baseline:           15.2 MB
After lynguine import:    132.4 MB  (+117 MB, mostly pandas/numpy)
After Interface import:   132.4 MB  (no additional overhead)
```

**Analysis**: Memory overhead dominated by pandas/numpy. Total footprint (~132 MB) is reasonable for long-running server process.

#### Performance Impact

**Current (without server mode)**:
- 1 call:    ~2.0s  (1.9s startup + 0.1s work)
- 10 calls:  ~20s   (19s startup + 1s work) - **95% overhead**
- 100 calls: ~200s  (190s startup + 10s work) - **95% overhead**

**Projected (with server mode)**:
- 1 call:    ~2.0s  (1x - no benefit)
- 10 calls:  ~3.0s  (**6-7x faster**)
- 100 calls: ~12s   (**15-20x faster**)

### Conclusion: Server Mode is Justified

**Evidence**:
1. ✅ Startup cost is high (1.9s per call)
2. ✅ Cannot be significantly optimized (pandas is core dependency)
3. ✅ Server mode would provide major benefit (10-20x for repeated calls)
4. ✅ Memory overhead acceptable (132 MB)
5. ✅ Real use case (lamd makes multiple calls per operation)

**Decision**: Proceed with CIP-0008 implementation.

## Proposed Solution: Lynguine Server Mode

### Architecture Overview

```
┌─────────────────────────────────────────────────────────────┐
│                    Client Applications                       │
│              (lamd, CLI tools, scripts)                      │
└────────────────────────┬────────────────────────────────────┘
                         │
                         ▼ (lightweight IPC)
┌─────────────────────────────────────────────────────────────┐
│                 Lynguine Server Process                      │
│                                                              │
│  ┌────────────────────────────────────────────────────┐    │
│  │  Server Manager                                     │    │
│  │  - Process lifecycle                                │    │
│  │  - Request routing                                  │    │
│  │  - Session management                               │    │
│  └────────────────────────────────────────────────────┘    │
│                         │                                    │
│                         ▼                                    │
│  ┌────────────────────────────────────────────────────┐    │
│  │  Lynguine Core (already imported, initialized)     │    │
│  │  - Interface, Context                               │    │
│  │  - CustomDataFrame                                  │    │
│  │  - Compute engine                                   │    │
│  └────────────────────────────────────────────────────┘    │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

### Key Design Decisions

#### 1. Server Lifecycle

**Question**: How is the server started and stopped?

**Proposal**:
- **Auto-start**: Client checks if server running, starts if needed
- **Graceful shutdown**: Timeout after idle period (configurable)
- **Manual control**: Commands to start/stop explicitly

```python
# Client usage (transparent to user)
from lynguine.client import Interface

# Auto-starts server if needed
interface = Interface.from_file("config.yml")
data = interface.read()
# Uses server for all operations
```

#### 2. Communication Protocol

**Critical Consideration**: Windows portability

**Options Evaluated**:

| Protocol | Overhead | Platforms | Complexity | Verdict |
|----------|----------|-----------|------------|---------|
| Unix sockets | ~0.01ms | Unix/Mac only | Low | ❌ Not portable |
| Named Pipes | ~0.01ms | Windows only | Low | ❌ Not portable |
| HTTP/REST | ~1-5ms | All platforms | Medium | ✅ **Recommended** |
| gRPC | ~0.1-1ms | All platforms | High | ⚠️ Overkill |

**Key Insight**: Even with HTTP overhead, we win big:
- Startup cost avoided: **1,900ms**
- HTTP overhead: **~2ms per request**
- We can afford **100x more overhead** and still get 10-20x speedup

**Recommendation**: Use **HTTP/REST from the start** (not as Phase 2)

**Rationale**:
- ✅ **Cross-platform**: Works on Unix, macOS, Windows out of the box
- ✅ **Overhead acceptable**: 2ms vs 1,900ms savings = 950x benefit
- ✅ **Simple**: Python's http.server is built-in, well-understood
- ✅ **Debuggable**: Can use curl, browser, standard tools
- ✅ **Remote access**: Client and server can be on different machines
- ✅ **Network scenarios**: Enables distributed computing, shared servers
- ⚠️ **Only downside**: ~2ms vs ~0.01ms (but irrelevant given 1,900ms savings)
- ⚠️ **Security**: Must address authentication for remote access (see below)

**Performance Analysis**:
```
Scenario: 100 operations

Without server:
  100 × 1,900ms = 190,000ms = 190 seconds

With local HTTP server (127.0.0.1):
  Startup: 1,900ms
  Requests: 100 × 2ms = 200ms
  Total: 2,100ms = 2.1 seconds
  Improvement: 90x faster

With remote HTTP server (LAN):
  Startup: 1,900ms
  Requests: 100 × 5ms = 500ms  (network latency)
  Total: 2,400ms = 2.4 seconds
  Improvement: 79x faster
  Still excellent!

With remote HTTP server (WAN):
  Startup: 1,900ms
  Requests: 100 × 50ms = 5,000ms  (internet latency)
  Total: 6,900ms = 6.9 seconds
  Improvement: 27x faster
  Still significant, but latency matters

With Unix sockets (local only):
  Startup: 1,900ms
  Requests: 100 × 0.01ms = 1ms
  Total: 1,901ms = 1.9 seconds
  Improvement: 100x faster

Verdict: 
  - Local: HTTP vs Unix sockets = 2.1s vs 1.9s (0.2s difference)
  - Remote: Enables distributed computing scenarios
  - Network latency is acceptable for most use cases
  - Choose HTTP for portability + remote capability
```

#### 3. Data Isolation

**Critical**: Each request must be isolated (no state leakage)

**Implementation**:
- Server maintains no request-level state
- Each operation is stateless
- Configuration passed with each request (or cached with session ID)
- Results serialized and sent back (no shared memory)

#### 4. Error Handling

**Challenges**:
- Server crash should not affect client
- Bad request should not crash server
- Clear error propagation to client

**Implementation**:
- Try/except around all request handlers
- Structured error responses
- Client detects server crash and restarts
- Logging on both client and server sides

#### 5. Security and Remote Access

**HTTP enables remote access** (client and server on different machines)

**Use Cases**:
- **Local-only** (default): Server binds to `127.0.0.1:8765`
  - Fast (~2ms overhead)
  - Secure (not accessible from network)
  - Simplest deployment
  
- **Shared server**: Server binds to `0.0.0.0:8765`
  - Multiple users share one lynguine server
  - Reduces memory (one Python process instead of N)
  - Enables compute clusters
  - **Requires authentication**

**Security Model**:

**Phase 1-3** (Local only, no auth):
- Server binds to `127.0.0.1` only
- Not accessible from network
- Safe for single-user, local scenarios
- Configuration: `LYNGUINE_SERVER_HOST=127.0.0.1` (default)

**Phase 4** (Optional remote access with auth):
- Server can bind to `0.0.0.0` if explicitly configured
- **Requires authentication** (API keys, tokens)
- **Requires HTTPS** (TLS/SSL) for encrypted transport
- Configuration: `LYNGUINE_SERVER_AUTH=required`
- Use case: Shared compute server, team environments

**Authentication Options** (Phase 4):
1. **API Keys**: Simple, token-based authentication
2. **OAuth**: Integrate with organizational auth
3. **SSH Tunneling**: Leverage existing SSH infrastructure

**Decision**: Start with **local-only** (Phase 1-3), add **authenticated remote access** as Phase 4

**Rationale**:
- Most use cases are local (lamd, CLI tools)
- Remote access is valuable but not MVP
- Security is critical for remote access
- Can be added later without breaking changes

### API Design

#### Client API (Backward Compatible)

```python
# Option 1: Transparent local (preferred for most users)
from lynguine import Interface
# Automatically uses local server if available, falls back to direct

# Option 2: Explicit local server
from lynguine.client import ServerInterface
interface = ServerInterface.from_file("config.yml")

# Option 3: Remote server (Phase 4)
from lynguine.client import ServerInterface
interface = ServerInterface.from_file(
    "config.yml",
    server_url="http://compute-server.example.com:8765",
    api_key="your-api-key"  # Required for remote
)

# Option 4: Context manager
from lynguine.server import LynguineServer
with LynguineServer() as server:
    # Multiple operations
    data1 = server.read("file1.yml")
    data2 = server.read("file2.yml")
```

#### Server Commands

```bash
# Start server (local-only, default)
lynguine serve --daemon
# Binds to 127.0.0.1:8765

# Start server on specific port
lynguine serve --port=9000 --daemon

# Stop server
lynguine serve --stop

# Status
lynguine serve --status

# Configure idle timeout
lynguine serve --idle-timeout=300  # 5 minutes

# Phase 4: Remote access (requires authentication)
lynguine serve --host=0.0.0.0 --auth-required --daemon
# WARNING: Only use with authentication enabled
```

### Wire Protocol

**Simple REST API over HTTP**:

```python
# Endpoint structure
POST http://localhost:8765/api/read_data
POST http://localhost:8765/api/write_data
POST http://localhost:8765/api/compute
GET  http://localhost:8765/api/health

# Request format (JSON body)
{
    "config": {...},        # Interface configuration
    "params": {             # Operation-specific parameters
        "path": "...",
        "options": {...}
    }
}

# Response format (JSON)
{
    "status": "success",    # or "error"
    "result": {...},        # serialized data
    "error": null,          # or error message
    "timing": {             # performance metrics
        "server_ms": 10.5,
        "operation_ms": 8.2
    }
}
```

**Data serialization**:
- JSON for metadata and simple data
- Base64-encoded pickle for DataFrames (Python-native, efficient)
- HTTP chunked transfer for large responses
- Alternative: Arrow IPC format (future, for language-agnostic clients)

## Implementation Plan

### Phase 1: Proof of Concept (2 weeks)

**Goal**: Validate approach with minimal, cross-platform implementation

- [x] Profile current startup costs (baseline measurements) - **COMPLETED 2026-01-03**
  - Startup: 1.947s (pandas 1.223s, lynguine 0.548s)
  - Memory: 132 MB
  - Target improvement validated: 10-20x possible
- [ ] Implement basic HTTP server (Python http.server, single-threaded)
- [ ] Implement basic client (transparent connection via requests library)
- [ ] Support one operation: `read_data()`
- [ ] Test on Unix/macOS/Windows
- [ ] Benchmark performance vs direct calls
- [ ] Measure actual HTTP overhead
- [ ] Decision point: Is improvement sufficient?

**Success criteria**:
- Server starts and handles requests on all platforms
- Client can make repeated calls
- Performance improvement > 5x for 10 operations (target: 6-7x based on profiling)
- HTTP overhead < 5ms per request

### Phase 2: Core Features (3-4 weeks)

**Goal**: Production-ready single-user server

- [ ] Support all common operations (read, write, compute)
- [ ] Graceful error handling
- [ ] Auto-start/stop lifecycle
- [ ] Idle timeout
- [ ] Logging and diagnostics
- [ ] Basic tests (unit and integration)
- [ ] Documentation (basic usage)

**Success criteria**:
- lamd can use server mode
- All operations work correctly
- No data corruption or state leakage
- Performance improvement validated

### Phase 3: Robustness (2-3 weeks)

**Goal**: Reliable, production-quality

- [ ] Comprehensive error handling
- [ ] Server crash recovery
- [ ] Request timeout handling
- [ ] Memory leak prevention
- [ ] Comprehensive test suite
- [ ] Performance benchmarks
- [ ] User documentation

**Success criteria**:
- 100+ tests passing
- No memory leaks in long runs
- Clear error messages
- Migration guide for users

### Phase 4: Remote Access and Advanced Features (future)

**Goal**: Enable secure remote access and multi-user scenarios

**Remote Access Features**:
- [ ] Authentication system (API keys, tokens)
- [ ] Authorization (per-user permissions)
- [ ] HTTPS/TLS support (encrypted transport)
- [ ] Server binds to 0.0.0.0 (when explicitly configured)
- [ ] Multi-user support (resource isolation)
- [ ] Rate limiting (per-user quotas)

**Performance Features**:
- [ ] Request caching/memoization
- [ ] Parallel request handling (thread pool)
- [ ] Connection pooling
- [ ] Response compression

**Operations Features**:
- [ ] Monitoring and metrics dashboard
- [ ] Health checks and status API
- [ ] Graceful shutdown with request draining
- [ ] Server clustering (load balancing)

**Use Cases Enabled**:
- Shared compute server for a team
- Centralized lynguine service (reduces memory × N users)
- Cloud-based data processing
- Distributed computing workflows

## Performance Targets

**Based on profiling** (measured 2026-01-03):

| Scenario | Current | Target | Improvement |
|----------|---------|--------|-------------|
| Single call | ~2.0s | ~2.0s | 1x (no change) |
| 10 calls | ~20s | ~3.0s | **6-7x faster** |
| 100 calls | ~200s | ~12s | **15-20x faster** |

**Actual measurements**:
- ✅ Startup time: 1.947s (measured)
- ✅ Breakdown: pandas 1.223s, lynguine 0.548s, other 0.176s
- ✅ Memory usage: 132 MB (measured)
- ⏳ Server overhead per request: ~0.01s (estimated, to be validated in PoC)

## Backward Compatibility

**Critical**: Must not break existing code

**Strategy**:
- Server mode is **optional** (not required)
- Direct mode continues to work
- Client API is transparent (auto-detects server)
- Users can opt-in with `use_server=True` or environment variable

**Migration path**:
```python
# Old code (continues to work)
from lynguine import Interface
interface = Interface.from_file("config.yml")

# New code (same API, uses server if available)
from lynguine import Interface
interface = Interface.from_file("config.yml", use_server=True)

# Or via environment variable
export LYNGUINE_USE_SERVER=1
```

## Alternative Approaches Considered

### Alternative 1: Import Optimization Only

**Approach**: Defer heavy imports, optimize existing code

**Pros**:
- No architectural changes
- Simpler implementation
- No process management

**Cons**:
- Limited improvement (maybe 2-3x)
- Doesn't help with configuration parsing
- Still pays cost on every call

**Decision**: Worth doing as quick win, but insufficient alone

### Alternative 2: Persistent REPL

**Approach**: Keep Python process running, execute commands in context

**Pros**:
- Simpler than full server
- No serialization overhead

**Cons**:
- State management complexity
- Hard to isolate requests
- Error recovery difficult

**Decision**: Rejected - too fragile

### Alternative 3: In-Memory Caching

**Approach**: Cache loaded data in memory across calls

**Pros**:
- Can reduce repeated loads
- Simpler than server

**Cons**:
- Doesn't help with startup cost
- Complex cache invalidation
- Still pays import cost

**Decision**: Complementary, not sufficient alone

### Alternative 4: Per-Application Daemon

**Approach**: Each application runs its own persistent context

**Pros**:
- Application-specific optimization
- Simpler lifecycle

**Cons**:
- Doesn't generalize
- Multiple processes
- Duplicate effort

**Decision**: Rejected - prefer general solution

## Risks and Mitigations

### Risk 1: Complexity

**Risk**: Server mode adds significant complexity

**Mitigation**:
- Keep Phase 1 simple (proof of concept)
- Make server mode optional (not required)
- Comprehensive testing
- Clear documentation

### Risk 2: State Leakage

**Risk**: Requests accidentally share state, causing bugs

**Mitigation**:
- Stateless server design
- Request isolation enforced
- Comprehensive tests for isolation
- Clear documentation of constraints

### Risk 3: Process Management

**Risk**: Server lifecycle is fragile (crashes, hangs, leaks)

**Mitigation**:
- Automatic crash recovery
- Idle timeout
- Health checks
- Monitoring and logging

### Risk 4: Limited Improvement

**Risk**: Actual speedup is less than expected

**Mitigation**:
- Profile first (Phase 1)
- Measure baseline
- Set decision criteria
- Early validation before full implementation

### Risk 5: HTTP Overhead Worse Than Expected

**Risk**: HTTP overhead is higher than estimated (>5ms)

**Mitigation**:
- Measure actual overhead in Phase 1
- Even 10ms overhead gives 19x improvement (not 20x)
- Can optimize if needed (keep-alive, connection pooling)
- HTTP overhead is negligible vs 1,900ms startup cost

## Testing Strategy

### Unit Tests

- [ ] Server lifecycle (start, stop, restart)
- [ ] Request/response parsing
- [ ] Error handling
- [ ] Timeout behavior
- [ ] Data serialization/deserialization

### Integration Tests

- [ ] Client-server communication
- [ ] Multiple sequential requests
- [ ] Concurrent requests (future)
- [ ] Server crash recovery
- [ ] Long-running stability

### Performance Tests

- [ ] Startup time measurement
- [ ] Per-operation timing
- [ ] Memory usage tracking
- [ ] Benchmark vs direct mode

### Compatibility Tests

- [ ] Works with existing code (transparent)
- [ ] Falls back correctly when server unavailable
- [ ] lamd integration testing
- [ ] referia compatibility

## Success Metrics

**Phase 1 Decision Criteria**:
- [ ] Proof of concept works
- [ ] Performance improvement > 5x for 10 operations
- [ ] Implementation complexity acceptable

**Phase 2 Success Criteria**:
- [ ] lamd can use server mode in production
- [ ] All common operations work
- [ ] No known data corruption bugs
- [ ] Performance targets met

**Overall Success**:
- [ ] 10x speedup for 100 operations
- [ ] Adoption by lamd, other applications
- [ ] Positive user feedback
- [ ] Stable in production use

## Related

- Requirement: [REQ-0007](../requirements/req0007_fast-repeated-access.md) - Fast Repeated Access
  - **All acceptance criteria addressed** (see verification below)
- Backlog: [2026-01-03_profile-lynguine-startup-performance](../backlog/infrastructure/2026-01-03_profile-lynguine-startup-performance.md) (Completed)
- Tenets:
  - `explicit-infrastructure`: Server mode must maintain explicit behavior
  - `flow-based-processing`: Must work within flow-based processing model
- Related CIPs:
  - CIP-0007: Package separation (affects deployment model)

## Requirement Acceptance Criteria Verification

This CIP addresses all acceptance criteria from REQ-0007:

| Criterion | Status | How CIP Addresses |
|-----------|--------|-------------------|
| Repeated operations significantly faster | ✅ | 10-20x improvement (profiled and validated) |
| Startup overhead amortized | ✅ | Server mode design: 1 startup for N operations |
| Compatible with existing API | ✅ | Backward compatible, transparent client |
| Works for programmatic + CLI | ✅ | Both supported, same API |
| Data isolation (no state leakage) | ✅ | Stateless server design, isolated requests |
| Clear error messages | ✅ | Structured error responses, comprehensive handling |
| Memory reasonable for long-running | ✅ | 132 MB measured, stable footprint |
| Graceful shutdown and cleanup | ✅ | Idle timeout, health checks, request draining |
| Performance metrics documented | ✅ | Full profiling: 1.947s startup, 2ms per request |
| Cross-platform (Unix, Windows) | ✅ | HTTP/REST works on all platforms |

## Requirement Constraints Verification

This CIP respects all constraints from REQ-0007:

| Constraint | Status | How CIP Respects |
|------------|--------|------------------|
| Maintain explicitness (no hidden state) | ✅ | Stateless server, explicit requests/responses |
| Ensure data isolation | ✅ | Each request isolated, no shared state |
| Work within flow-based processing | ✅ | Server executes normal flow processing |
| Not break existing applications | ✅ | Optional server mode, graceful fallback |
| Work on all platforms | ✅ | HTTP/REST (not Unix sockets) |
| Handle crashes gracefully | ✅ | Client auto-recovery, server restart |
| Reasonable memory footprint | ✅ | 132 MB, same as normal lynguine |

## References

- Python http.server: https://docs.python.org/3/library/http.server.html
- Python requests library: https://docs.python-requests.org/
- REST API design: https://restfulapi.net/
- Python multiprocessing: https://docs.python.org/3/library/multiprocessing.html

## Author and Date

- **Author**: Neil Lawrence
- **Created**: 2026-01-03
- **Status**: Proposed (awaiting investigation and feedback)

## Next Steps

1. **Profile current performance** (establish baseline)
2. **Analyze lamd usage patterns** (understand requirements)
3. **Review this CIP** with team
4. **Decide**: Accept, revise, or explore alternatives
5. **If accepted**: Begin Phase 1 implementation

